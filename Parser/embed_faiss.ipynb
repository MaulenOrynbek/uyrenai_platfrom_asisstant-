{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d210ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache up to date. Skipping embedding and index rebuild.\n",
      "Artifacts already exist and match current data. Nothing to do.\n"
     ]
    }
   ],
   "source": [
    "# Build combined text+metadata, embed with OpenAI, and save artifacts for FAISS search\n",
    "# !pip install -q pandas numpy faiss-cpu openai==1.*\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from openai import OpenAI\n",
    "\n",
    "# Configuration\n",
    "INPUT_CSV = \"CHUNKS_DB.csv\"           # expects columns: id, text, metadata\n",
    "CACHE_DIR = \"rag_cache\"\n",
    "EMBED_MODEL = \"text-embedding-3-small\"  # 1536-dim vectors\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise RuntimeError(\"Set OPENAI_API_KEY in your environment before running this cell.\")\n",
    "\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "INDEX_PATH = os.path.join(CACHE_DIR, \"faiss.index\")\n",
    "IDMAP_PATH = os.path.join(CACHE_DIR, \"id_map.npy\")\n",
    "TEXTS_PATH = os.path.join(CACHE_DIR, \"rag_texts.jsonl\")\n",
    "MANIFEST_PATH = os.path.join(CACHE_DIR, \"manifest.json\")\n",
    "\n",
    "# 1) Load data\n",
    "chunks_df = pd.read_csv(INPUT_CSV)\n",
    "required_cols = {\"id\", \"text\", \"metadata\"}\n",
    "if not required_cols.issubset(set(chunks_df.columns)):\n",
    "    raise ValueError(f\"Input must contain columns: {sorted(required_cols)}\")\n",
    "\n",
    "# 2) Build a single combined field for RAG (text + JSON-serialized metadata)\n",
    "def _normalize_text(value):\n",
    "    try:\n",
    "        if pd.isna(value):\n",
    "            return \"\"\n",
    "    except Exception:\n",
    "        pass\n",
    "    return str(value).strip()\n",
    "\n",
    "def _metadata_to_string(value):\n",
    "    if isinstance(value, dict):\n",
    "        return json.dumps(value, ensure_ascii=False, sort_keys=True)\n",
    "    if isinstance(value, str):\n",
    "        v = value.strip()\n",
    "        try:\n",
    "            parsed = json.loads(v)\n",
    "            if isinstance(parsed, dict):\n",
    "                return json.dumps(parsed, ensure_ascii=False, sort_keys=True)\n",
    "        except Exception:\n",
    "            pass\n",
    "        return v\n",
    "    try:\n",
    "        if pd.isna(value):\n",
    "            return \"\"\n",
    "    except Exception:\n",
    "        pass\n",
    "    return str(value)\n",
    "\n",
    "chunks_df[\"rag_text\"] = (\n",
    "    chunks_df[\"text\"].apply(_normalize_text)\n",
    "    + \"\\n\\nMETADATA: \"\n",
    "    + chunks_df[\"metadata\"].apply(_metadata_to_string)\n",
    ")\n",
    "\n",
    "rag_texts = chunks_df[\"rag_text\"].astype(str).tolist()\n",
    "ids = chunks_df[\"id\"].to_numpy()\n",
    "\n",
    "# 3) Compute dataset hash to enable caching across runs\n",
    "joined = \"\\n\".join(rag_texts)\n",
    "dataset_hash = hashlib.sha256(joined.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "# If cache exists and matches, skip embedding\n",
    "use_cache = (\n",
    "    os.path.exists(INDEX_PATH)\n",
    "    and os.path.exists(IDMAP_PATH)\n",
    "    and os.path.exists(TEXTS_PATH)\n",
    "    and os.path.exists(MANIFEST_PATH)\n",
    ")\n",
    "if use_cache:\n",
    "    try:\n",
    "        with open(MANIFEST_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "            manifest = json.load(f)\n",
    "        if manifest.get(\"dataset_hash\") == dataset_hash and manifest.get(\"embed_model\") == EMBED_MODEL:\n",
    "            print(\"Cache up to date. Skipping embedding and index rebuild.\")\n",
    "        else:\n",
    "            use_cache = False\n",
    "    except Exception:\n",
    "        use_cache = False\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "if not use_cache:\n",
    "    # 4) Create embeddings via OpenAI in batches\n",
    "    vectors = []\n",
    "    for start in range(0, len(rag_texts), BATCH_SIZE):\n",
    "        end = min(start + BATCH_SIZE, len(rag_texts))\n",
    "        resp = client.embeddings.create(model=EMBED_MODEL, input=rag_texts[start:end])\n",
    "        vectors.extend([d.embedding for d in resp.data])\n",
    "        print(f\"Embedded {end}/{len(rag_texts)}\")\n",
    "\n",
    "    emb = np.array(vectors, dtype=np.float32)\n",
    "    # Normalize for cosine similarity using inner product in FAISS\n",
    "    emb = emb / np.linalg.norm(emb, axis=1, keepdims=True)\n",
    "\n",
    "    # 5) Build FAISS index and save artifacts\n",
    "    dim = emb.shape[1]\n",
    "    index = faiss.IndexFlatIP(dim)\n",
    "    index.add(emb)\n",
    "\n",
    "    faiss.write_index(index, INDEX_PATH)\n",
    "    np.save(IDMAP_PATH, ids)\n",
    "    with open(TEXTS_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        for _id, txt in zip(ids, rag_texts):\n",
    "            f.write(json.dumps({\"id\": int(_id), \"rag_text\": txt}, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    manifest = {\n",
    "        \"dataset_hash\": dataset_hash,\n",
    "        \"embed_model\": EMBED_MODEL,\n",
    "        \"num_vectors\": int(index.ntotal),\n",
    "        \"dim\": int(dim),\n",
    "        \"created_at\": int(time.time()),\n",
    "        \"source\": os.path.abspath(INPUT_CSV),\n",
    "    }\n",
    "    with open(MANIFEST_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(manifest, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"Built and saved FAISS index with {index.ntotal} vectors (dim={dim}).\")\n",
    "    print(f\"Artifacts saved to: {CACHE_DIR}\")\n",
    "else:\n",
    "    print(\"Artifacts already exist and match current data. Nothing to do.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
